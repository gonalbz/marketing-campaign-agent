{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f0289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (0.3.23)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.25-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langchain-openai) (1.86.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (6.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.64.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.66->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-openai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.86.0->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.3.25-py3-none-any.whl (69 kB)\n",
      "Downloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
      "Installing collected packages: langchain-core, langchain-openai\n",
      "\n",
      "  Attempting uninstall: langchain-core\n",
      "\n",
      "    Found existing installation: langchain-core 0.3.65\n",
      "\n",
      "    Uninstalling langchain-core-0.3.65:\n",
      "\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "      Successfully uninstalled langchain-core-0.3.65\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "  Attempting uninstall: langchain-openai\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "    Found existing installation: langchain-openai 0.3.23\n",
      "   ---------------------------------------- 0/2 [langchain-core]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "    Uninstalling langchain-openai-0.3.23:\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "      Successfully uninstalled langchain-openai-0.3.23\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   ---------------------------------------- 2/2 [langchain-openai]\n",
      "\n",
      "Successfully installed langchain-core-0.3.66 langchain-openai-0.3.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (12.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\sherryshen\\anaconda3\\lib\\site-packages (from pyarrow) (2.2.6)\n"
     ]
    }
   ],
   "source": [
    "# pip install databricks-sdk openai\n",
    "# !pip install databricks-sql-connector\n",
    "# !pip install --upgrade numpy pandas\n",
    "# !pip install pandas==2.2.2\n",
    "# !pip install -U langchain-openai\n",
    "# !pip install numpy<2\n",
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5667cf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Enter campaign topic: Plan a Back-to-School campaign. Focus on writing tools, and classroom furniture\n",
      "â³ Step 1: Loading data from Databricks...\n",
      "2024-12-30 00:00:00\n",
      "âš™ï¸ Step 2: Analyzing internal insights...\n",
      "SELECT \n",
      "    `Sub-Category`,\n",
      "    `Region`,\n",
      "    YEAR(`Order_Date`) AS year,\n",
      "    SUM(Sales) AS total_sales,\n",
      "    SUM(Profit) AS total_profit\n",
      "FROM Orders\n",
      "WHERE `Sub-Category` IN ('Binders', 'Paper', 'Labels', 'Art', 'Chairs', 'Tables')\n",
      "GROUP BY `Sub-Category`, `Region`, YEAR(`Order_Date`)\n",
      "- Art sub-category in the Central region saw a significant increase in both sales and profit YoY, with sales increasing by 50.75% and profit by 90.44%.\n",
      "- Binders sub-category in the South region experienced a substantial sales increase of 170.98% YoY, but a decrease in profit by 34.31%.\n",
      "- Chairs sub-category in the South region had a notable increase in sales by 147.29% and profit by 51.33% YoY.\n",
      "- Labels sub-category in the South region also showed a significant increase in both sales and profit YoY, with sales increasing by 89.41% and profit by 54.31%.\n",
      "- Paper sub-category in the East region had a substantial increase in both sales and profit YoY, with sales increasing by 58.18% and profit by 65.50%.\n",
      "- Tables sub-category in the South region experienced a significant decrease in both sales and profit YoY, with sales decreasing by 12.87% and profit by 9275.47%.\n",
      "ðŸ§  Generating campaign report...\n",
      "1. Executive Summary:\n",
      "The Back-to-School campaign for writing tools and classroom furniture has seen significant growth in sales and profit in various categories and regions. The Northeast U.S. is targeted for bundle offers, while Amazon is offering discounts nationwide. Influencer campaigns on TikTok are trending, driving interest in the campaign.\n",
      "\n",
      "2. Key Insights:\n",
      "- There was a substantial increase in sales and profit in the Central region, with sales increasing by 50.75% and profit by 90.44% Year-over-Year (YoY).\n",
      "- Binders in the South region experienced a sales increase of 170.98% YoY, but saw a decrease in profit by 34.31%.\n",
      "- Chairs in the South region had a notable increase in sales by 147.29% and profit by 51.33% YoY.\n",
      "- Labels in the South region showed a significant increase in both sales by 89.41% and profit by 54.31% YoY.\n",
      "- Tables in the South region experienced a significant decrease in both sales by 12.87% and profit by 9275.47%.\n",
      "\n",
      "3. Recommended Actions:\n",
      "- Increase advertising and promotion efforts in the Central region to capitalize on the significant growth in sales and profit.\n",
      "- Consider adjusting pricing strategies for binders in the South region to maintain profit while continuing to increase sales.\n",
      "- Explore opportunities to expand the influencer campaign to reach a wider audience and capitalize on the trend.\n",
      "- Evaluate the marketing strategy for tables in the South region to reverse the decline in sales and profit.\n"
     ]
    }
   ],
   "source": [
    "# === 1. Imports & Config ===\n",
    "import os\n",
    "import pandas as pd\n",
    "from databricks import sql\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Databricks config\n",
    "DATABRICKS_SERVER_HOSTNAME = os.getenv(\"DATABRICKS_SERVER_HOSTNAME\")\n",
    "DATABRICKS_ACCESS_TOKEN = os.getenv(\"DATABRICKS_ACCESS_TOKEN\")\n",
    "WAREHOUSE_ID = os.getenv(\"WAREHOUSE_ID\")\n",
    "\n",
    "CATALOG = \"main\"\n",
    "SCHEMA = \"bi_schema\"\n",
    "TABLE = \"orders_superstore\"\n",
    "\n",
    "# LLM setup\n",
    "#llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# === 2. Functions ===\n",
    "\n",
    "def load_table_from_databricks(catalog, schema, table):\n",
    "    connection = sql.connect(\n",
    "        server_hostname=DATABRICKS_SERVER_HOSTNAME,\n",
    "        http_path=f\"/sql/1.0/warehouses/{WAREHOUSE_ID}\",\n",
    "        access_token=DATABRICKS_ACCESS_TOKEN\n",
    "    )\n",
    "    query = f\"SELECT * FROM {catalog}.{schema}.{table}\"\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    rows = cursor.fetchall()\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return df\n",
    "\n",
    "def analyze_internal_insights(df: pd.DataFrame, user_prompt: str, table_name: str = \"Orders\"):\n",
    "    # Step 1: Extract category values\n",
    "    all_categories = df[\"Category\"].dropna().unique().tolist()\n",
    "    all_subcategories = df[\"Sub-Category\"].dropna().unique().tolist()\n",
    "   \n",
    "    # Step 2: Use LLM to map prompt to subcategories\n",
    "    category_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are helping analyze a sales dataset. The dataset includes:\n",
    "\n",
    "Main Categories: {categories}\n",
    "Sub-Categories: {subcategories}\n",
    "\n",
    "Given this campaign prompt:\n",
    "\"{user_prompt}\"\n",
    "\n",
    "Return a dedupped Python list of relevant Sub-Categories that match the prompt.\n",
    "Example: [\"Binders\", \"Art\", \"Appliances\"]\n",
    "\"\"\")\n",
    "\n",
    "    messages = category_prompt.format_messages(\n",
    "        categories=all_categories,\n",
    "        subcategories=all_subcategories,\n",
    "        user_prompt=user_prompt\n",
    "    )\n",
    "    response = llm.invoke(messages).content\n",
    "\n",
    "    try:\n",
    "        matched_subcategories = eval(response)\n",
    "    except:\n",
    "        return \"LLM response could not be parsed. Response was:\\n\" + response, None, None, None\n",
    "\n",
    "    if not matched_subcategories:\n",
    "        return \"No relevant sub-categories found by the LLM.\", None, None, None\n",
    "\n",
    "    # Step 3: Filter data\n",
    "    df_filtered = df[df[\"Sub-Category\"].isin(matched_subcategories)].copy()\n",
    "    df_filtered[\"Order_Date\"] = pd.to_datetime(df_filtered[\"Order_Date\"])\n",
    "    df_filtered[\"year\"] = df_filtered[\"Order_Date\"].dt.year\n",
    "\n",
    "    # Step 4: Identify the latest two years in the dataset\n",
    "    latest_years = sorted(df_filtered[\"year\"].dropna().unique())[-2:]\n",
    "    if len(latest_years) < 2:\n",
    "        raise ValueError(\"Not enough years of data for YoY comparison.\")\n",
    "\n",
    "    year_new, year_old = latest_years[1], latest_years[0]\n",
    "\n",
    "    # Step 5: YoY aggregation\n",
    "    grouped = df_filtered.groupby([\"Sub-Category\", \"Region\", \"year\"]).agg({\n",
    "        \"Sales\": \"sum\",\n",
    "        \"Profit\": \"sum\"\n",
    "    }).reset_index()\n",
    "\n",
    "    df_new = grouped[grouped[\"year\"] == year_new].set_index([\"Sub-Category\", \"Region\"])\n",
    "    df_old = grouped[grouped[\"year\"] == year_old].set_index([\"Sub-Category\", \"Region\"])\n",
    "\n",
    "    yoy = df_new.join(df_old, lsuffix=f\"_{year_new}\", rsuffix=f\"_{year_old}\", how=\"inner\")\n",
    "    yoy[\"sales_yoy\"] = ((yoy[f\"Sales_{year_new}\"] - yoy[f\"Sales_{year_old}\"]) / yoy[f\"Sales_{year_old}\"]) * 100\n",
    "    yoy[\"profit_yoy\"] = ((yoy[f\"Profit_{year_new}\"] - yoy[f\"Profit_{year_old}\"]) / yoy[f\"Profit_{year_old}\"]) * 100\n",
    "    yoy.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    # Step 6: SQL generation\n",
    "    sql_list = \", \".join(f\"'{s}'\" for s in matched_subcategories)\n",
    "    sql_script = f\"\"\"\n",
    "SELECT \n",
    "    `Sub-Category`,\n",
    "    `Region`,\n",
    "    YEAR(`Order_Date`) AS year,\n",
    "    SUM(Sales) AS total_sales,\n",
    "    SUM(Profit) AS total_profit\n",
    "FROM {table_name}\n",
    "WHERE `Sub-Category` IN ({sql_list})\n",
    "GROUP BY `Sub-Category`, `Region`, YEAR(`Order_Date`)\n",
    "\"\"\".strip()\n",
    "\n",
    "    # Step 7: Insights summary\n",
    "    summary_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a BI analyst. Summarize the following YoY data in clear bullet points.\n",
    "Focus on major % increases or decreases in sales or profit by sub-category and region.\n",
    "\n",
    "Data:\n",
    "{yoy_data}\n",
    "\"\"\")\n",
    "    summary_input = summary_prompt.format_messages(yoy_data=yoy.to_csv(index=False))\n",
    "    insight_summary = llm.invoke(summary_input).content\n",
    "\n",
    "    return df_filtered, yoy, sql_script, insight_summary#, matched_subcategories\n",
    "\n",
    "web_summary = [\n",
    "    \"Target is promoting bundle offers in Northeast U.S.\",\n",
    "    \"Amazon is running 15% discounts on school supplies nationwide.\",\n",
    "    \"Back-to-school themed influencer campaigns are trending on TikTok.\"\n",
    "]\n",
    "\n",
    "def generate_campaign_report(web_summaries,insight_summary, user_topic):\n",
    "    prompt = f\"\"\"\n",
    "You're a marketing analyst. Create a one-page summary report combining web insights and sales data insight summary for a {user_topic}.\n",
    "Focus on trends, regional patterns, and recommended actions.\n",
    "\n",
    "Web insights:\n",
    "{chr(10).join(f\"- {ws}\" for ws in web_summaries)}\n",
    "\n",
    "Sales data summaries:\n",
    "{chr(10).join(f\"- {cs}\" for cs in insight_summary)}\n",
    "\n",
    "Return output as:\n",
    "1. Executive Summary\n",
    "2. Key Insights\n",
    "3. Recommended Actions\n",
    "\"\"\"\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "# # === 3. Execution Flow ===\n",
    "if __name__ == \"__main__\":\n",
    "    user_topic = input(\"ðŸ“Œ Enter campaign topic: \")\n",
    "    print(\"â³ Step 1: Loading data from Databricks...\")\n",
    "    df = load_table_from_databricks(CATALOG, SCHEMA, TABLE)\n",
    "    print(df[\"Order_Date\"].max())\n",
    "\n",
    "\n",
    "    print(\"âš™ï¸ Step 2: Analyzing internal insights...\")\n",
    "    df_filtered, yoy, sql_script, insight_summary = analyze_internal_insights(df, user_topic)\n",
    "    print(sql_script)\n",
    "    #print(yoy)\n",
    "    print(insight_summary)\n",
    "\n",
    "    if insight_summary:\n",
    "        print(\"ðŸ§  Generating campaign report...\")\n",
    "        report = generate_campaign_report(web_summary,insight_summary, user_topic)\n",
    "        print(report)\n",
    "    else:\n",
    "        print(\"âŒ No insights generated. Please refine your prompt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e83f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Plan a Back-to-School campaign. Focus on binders, tables, writing tools, and classroom furniture.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
